{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23a71c0-f381-44eb-8833-75e8ca99d11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d86f71-791c-4afd-9bdf-00552ecab14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.2822 - loss: 3.4676 - val_accuracy: 0.4756 - val_loss: 1.7540 - learning_rate: 0.0100\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.4591 - loss: 1.7944 - val_accuracy: 0.5059 - val_loss: 1.6213 - learning_rate: 0.0099\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.4821 - loss: 1.6997 - val_accuracy: 0.5025 - val_loss: 1.6379 - learning_rate: 0.0098\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.4872 - loss: 1.6843 - val_accuracy: 0.5275 - val_loss: 1.6027 - learning_rate: 0.0097\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.4928 - loss: 1.6825 - val_accuracy: 0.5038 - val_loss: 1.6628 - learning_rate: 0.0096\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.4933 - loss: 1.6831 - val_accuracy: 0.5240 - val_loss: 1.6151 - learning_rate: 0.0095\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.4916 - loss: 1.6849 - val_accuracy: 0.4690 - val_loss: 1.7477 - learning_rate: 0.0094\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.4972 - loss: 1.6880 - val_accuracy: 0.5268 - val_loss: 1.6102 - learning_rate: 0.0093\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.4852 - loss: 1.7116 - val_accuracy: 0.5308 - val_loss: 1.5910 - learning_rate: 0.0092\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.4958 - loss: 1.6924 - val_accuracy: 0.5070 - val_loss: 1.6526 - learning_rate: 0.0091\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.4994 - loss: 1.6813 - val_accuracy: 0.4923 - val_loss: 1.7367 - learning_rate: 0.0090\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.4910 - loss: 1.7076 - val_accuracy: 0.4981 - val_loss: 1.6898 - learning_rate: 0.0090\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.5108 - loss: 1.6747 - val_accuracy: 0.5460 - val_loss: 1.5740 - learning_rate: 0.0089\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.5082 - loss: 1.6649 - val_accuracy: 0.5508 - val_loss: 1.5401 - learning_rate: 0.0088\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5082 - loss: 1.6703 - val_accuracy: 0.5171 - val_loss: 1.6191 - learning_rate: 0.0087\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.5052 - loss: 1.6655 - val_accuracy: 0.5254 - val_loss: 1.6407 - learning_rate: 0.0086\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5090 - loss: 1.6714 - val_accuracy: 0.5321 - val_loss: 1.6074 - learning_rate: 0.0085\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5036 - loss: 1.6773 - val_accuracy: 0.5194 - val_loss: 1.6361 - learning_rate: 0.0084\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5022 - loss: 1.6893 - val_accuracy: 0.5307 - val_loss: 1.6180 - learning_rate: 0.0084\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5055 - loss: 1.6808 - val_accuracy: 0.5386 - val_loss: 1.5823 - learning_rate: 0.0083\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.2796 - loss: 3.4807 - val_accuracy: 0.4689 - val_loss: 1.8149 - learning_rate: 0.0100\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.4592 - loss: 1.7845 - val_accuracy: 0.4853 - val_loss: 1.7384 - learning_rate: 0.0100\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.4737 - loss: 1.7113 - val_accuracy: 0.5060 - val_loss: 1.6183 - learning_rate: 0.0100\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.4849 - loss: 1.6981 - val_accuracy: 0.5020 - val_loss: 1.6626 - learning_rate: 0.0100\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.4866 - loss: 1.7091 - val_accuracy: 0.5330 - val_loss: 1.5955 - learning_rate: 0.0100\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5171 - loss: 1.6092 - val_accuracy: 0.5640 - val_loss: 1.4655 - learning_rate: 0.0050\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5246 - loss: 1.5577 - val_accuracy: 0.5556 - val_loss: 1.4693 - learning_rate: 0.0050\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5282 - loss: 1.5472 - val_accuracy: 0.5482 - val_loss: 1.4983 - learning_rate: 0.0050\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5358 - loss: 1.5398 - val_accuracy: 0.5527 - val_loss: 1.4994 - learning_rate: 0.0050\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5318 - loss: 1.5494 - val_accuracy: 0.5528 - val_loss: 1.5068 - learning_rate: 0.0050\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5535 - loss: 1.4837 - val_accuracy: 0.5757 - val_loss: 1.4305 - learning_rate: 0.0025\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5596 - loss: 1.4599 - val_accuracy: 0.5766 - val_loss: 1.4251 - learning_rate: 0.0025\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5597 - loss: 1.4476 - val_accuracy: 0.5758 - val_loss: 1.4053 - learning_rate: 0.0025\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5598 - loss: 1.4517 - val_accuracy: 0.5762 - val_loss: 1.4225 - learning_rate: 0.0025\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5655 - loss: 1.4423 - val_accuracy: 0.5678 - val_loss: 1.4486 - learning_rate: 0.0025\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5778 - loss: 1.4018 - val_accuracy: 0.5806 - val_loss: 1.3986 - learning_rate: 0.0012\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5800 - loss: 1.3915 - val_accuracy: 0.5963 - val_loss: 1.3581 - learning_rate: 0.0012\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5903 - loss: 1.3713 - val_accuracy: 0.6035 - val_loss: 1.3440 - learning_rate: 0.0012\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5879 - loss: 1.3766 - val_accuracy: 0.5992 - val_loss: 1.3514 - learning_rate: 0.0012\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5922 - loss: 1.3696 - val_accuracy: 0.6022 - val_loss: 1.3374 - learning_rate: 0.0012\n",
      "Training Time - Exponential Decay: 258.69s\n",
      "Training Time - Step Decay: 249.65s\n",
      "Test Accuracy - Exponential Decay: 53.86%\n",
      "Test Accuracy - Step Decay: 60.22%\n",
      "\n",
      "Exponential Decay:\n",
      "Epoch 1: Training Accuracy = 35.74%, Validation Accuracy = 47.56%\n",
      "Epoch 2: Training Accuracy = 46.63%, Validation Accuracy = 50.59%\n",
      "Epoch 3: Training Accuracy = 48.12%, Validation Accuracy = 50.25%\n",
      "Epoch 4: Training Accuracy = 48.78%, Validation Accuracy = 52.75%\n",
      "Epoch 5: Training Accuracy = 48.64%, Validation Accuracy = 50.38%\n",
      "Epoch 6: Training Accuracy = 49.32%, Validation Accuracy = 52.40%\n",
      "Epoch 7: Training Accuracy = 49.50%, Validation Accuracy = 46.90%\n",
      "Epoch 8: Training Accuracy = 49.69%, Validation Accuracy = 52.68%\n",
      "Epoch 9: Training Accuracy = 48.73%, Validation Accuracy = 53.08%\n",
      "Epoch 10: Training Accuracy = 49.45%, Validation Accuracy = 50.70%\n",
      "Epoch 11: Training Accuracy = 49.89%, Validation Accuracy = 49.23%\n",
      "Epoch 12: Training Accuracy = 49.47%, Validation Accuracy = 49.81%\n",
      "Epoch 13: Training Accuracy = 50.52%, Validation Accuracy = 54.60%\n",
      "Epoch 14: Training Accuracy = 50.86%, Validation Accuracy = 55.08%\n",
      "Epoch 15: Training Accuracy = 50.56%, Validation Accuracy = 51.71%\n",
      "Epoch 16: Training Accuracy = 50.29%, Validation Accuracy = 52.54%\n",
      "Epoch 17: Training Accuracy = 50.14%, Validation Accuracy = 53.21%\n",
      "Epoch 18: Training Accuracy = 50.16%, Validation Accuracy = 51.94%\n",
      "Epoch 19: Training Accuracy = 50.17%, Validation Accuracy = 53.07%\n",
      "Epoch 20: Training Accuracy = 50.52%, Validation Accuracy = 53.86%\n",
      "\n",
      "Step Decay:\n",
      "Epoch 1: Training Accuracy = 35.69%, Validation Accuracy = 46.89%\n",
      "Epoch 2: Training Accuracy = 46.42%, Validation Accuracy = 48.53%\n",
      "Epoch 3: Training Accuracy = 47.52%, Validation Accuracy = 50.60%\n",
      "Epoch 4: Training Accuracy = 48.37%, Validation Accuracy = 50.20%\n",
      "Epoch 5: Training Accuracy = 48.88%, Validation Accuracy = 53.30%\n",
      "Epoch 6: Training Accuracy = 51.64%, Validation Accuracy = 56.40%\n",
      "Epoch 7: Training Accuracy = 52.34%, Validation Accuracy = 55.56%\n",
      "Epoch 8: Training Accuracy = 52.46%, Validation Accuracy = 54.82%\n",
      "Epoch 9: Training Accuracy = 53.27%, Validation Accuracy = 55.27%\n",
      "Epoch 10: Training Accuracy = 52.98%, Validation Accuracy = 55.28%\n",
      "Epoch 11: Training Accuracy = 55.38%, Validation Accuracy = 57.57%\n",
      "Epoch 12: Training Accuracy = 55.64%, Validation Accuracy = 57.66%\n",
      "Epoch 13: Training Accuracy = 55.86%, Validation Accuracy = 57.58%\n",
      "Epoch 14: Training Accuracy = 56.07%, Validation Accuracy = 57.62%\n",
      "Epoch 15: Training Accuracy = 56.25%, Validation Accuracy = 56.78%\n",
      "Epoch 16: Training Accuracy = 57.82%, Validation Accuracy = 58.06%\n",
      "Epoch 17: Training Accuracy = 57.97%, Validation Accuracy = 59.63%\n",
      "Epoch 18: Training Accuracy = 58.30%, Validation Accuracy = 60.35%\n",
      "Epoch 19: Training Accuracy = 58.35%, Validation Accuracy = 59.92%\n",
      "Epoch 20: Training Accuracy = 58.84%, Validation Accuracy = 60.22%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import time\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
    "y_train, y_test = tf.keras.utils.to_categorical(y_train, 10), tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "def create_shallow_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),  # Add dropout to prevent overfitting\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.3),  # Dropout in Dense layer\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, optimizer, epochs, use_scheduler=False, schedule_func=None):\n",
    "    if use_scheduler:\n",
    "        lr_schedule = tf.keras.callbacks.LearningRateScheduler(schedule_func)\n",
    "        callbacks = [lr_schedule]\n",
    "    else:\n",
    "        callbacks = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=64, \n",
    "                        validation_data=(x_test, y_test), callbacks=callbacks, verbose=1)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Extract training and validation accuracy\n",
    "    training_accuracy = history.history['accuracy']\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "    return end_time - start_time, training_accuracy, validation_accuracy\n",
    "\n",
    "# Exponential Decay Scheduler\n",
    "def exponential_decay_schedule(epoch):\n",
    "    initial_lr = 0.01\n",
    "    decay_rate = 0.1\n",
    "    decay_steps = 10\n",
    "    lr = initial_lr * tf.math.exp(-decay_rate * epoch / decay_steps)\n",
    "    return float(lr)\n",
    "\n",
    "# Step Decay Scheduler\n",
    "def step_decay_schedule(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop_factor = 0.5\n",
    "    epochs_drop = 5\n",
    "    lr = initial_lr * (drop_factor ** (epoch // epochs_drop))\n",
    "    return float(lr)\n",
    "\n",
    "# Experiment 1: SGD with Exponential Decay\n",
    "model_exp_decay = create_shallow_model()\n",
    "optimizer_exp_decay = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "time_exp_decay, train_acc_exp_decay, val_acc_exp_decay = train_model(\n",
    "    model_exp_decay, optimizer_exp_decay, epochs=20, use_scheduler=True, schedule_func=exponential_decay_schedule\n",
    ")\n",
    "\n",
    "# Experiment 2: SGD with Step Decay\n",
    "model_step_decay = create_shallow_model()\n",
    "optimizer_step_decay = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "time_step_decay, train_acc_step_decay, val_acc_step_decay = train_model(\n",
    "    model_step_decay, optimizer_step_decay, epochs=20, use_scheduler=True, schedule_func=step_decay_schedule\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"Training Time - Exponential Decay: {time_exp_decay:.2f}s\")\n",
    "print(f\"Training Time - Step Decay: {time_step_decay:.2f}s\")\n",
    "\n",
    "# Evaluate models\n",
    "_, accuracy_exp_decay = model_exp_decay.evaluate(x_test, y_test, verbose=0)\n",
    "_, accuracy_step_decay = model_step_decay.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test Accuracy - Exponential Decay: {accuracy_exp_decay * 100:.2f}%\")\n",
    "print(f\"Test Accuracy - Step Decay: {accuracy_step_decay * 100:.2f}%\")\n",
    "\n",
    "# Print training and validation accuracy for Exponential Decay\n",
    "print(\"\\nExponential Decay:\")\n",
    "for epoch in range(20):\n",
    "    print(f\"Epoch {epoch + 1}: Training Accuracy = {train_acc_exp_decay[epoch] * 100:.2f}%, Validation Accuracy = {val_acc_exp_decay[epoch] * 100:.2f}%\")\n",
    "\n",
    "# Print training and validation accuracy for Step Decay\n",
    "print(\"\\nStep Decay:\")\n",
    "for epoch in range(20):\n",
    "    print(f\"Epoch {epoch + 1}: Training Accuracy = {train_acc_step_decay[epoch] * 100:.2f}%, Validation Accuracy = {val_acc_step_decay[epoch] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23faea82-b9fe-4d64-b6f5-a961036d5634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
